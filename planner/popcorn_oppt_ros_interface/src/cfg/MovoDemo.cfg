# General-purpose settings.
verbose = true
logPath = log
overwriteExistingLogFiles = true
logFilePostfix =
saveParticles = true
deactivateVisualization = false

##################################################################################################
##################################################################################################
#### Loaded plugins
##################################################################################################
##################################################################################################
[plugins]
heuristicPlugin = libmovoGraspingHeuristicPlugin.so

planningRewardPlugin = libmovoGraspingRewardPlugin.so
executionRewardPlugin = libmovoGraspingRewardPlugin.so

planningTerminalPlugin = libmovoGraspingTerminalPlugin.so
executionTerminalPlugin = libmovoGraspingTerminalPlugin.so

planningTransitionPlugin = libmovoGraspingTransitionPlugin.so
executionTransitionPlugin = libmovoGraspingTransitionPlugin.so

planningObservationPlugin = libmovoGraspingObservationPlugin.so
executionObservationPlugin = libmovoGraspingObservationPlugin.so

executionInitialBeliefPlugin = libmovoGraspingInitialBeliefPlugin.so
planningInitialBeliefPlugin = libmovoGraspingInitialBeliefPlugin.so

[transitionPluginOptions]
#errorMargins = [0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0030]

# In case uniform error distribution is used
errorMargins = [0.0, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055]

jointCovariances = [0.0, 0.00006, 0.00006, 0.00006, 0.00006, 0.00006, 0.00006]

# Required for velocity control
handLinkName = right_ee_link
objectDistanceCheckedLink = right_knuckle_link
gripperLinkName = right_wrist_3_link
targetLinkName = TargetObject::cylinderLink

maxVerticalGraspDist = 0.045
maxHorizontalGraspDist = 0.00075
#maxHorizontalGraspDist = 0.03
fingerClosingAngle = 1.0

# The time a step takes in the execution environment
stepDuration = 750
#stepDuration = 2000

# Probability that a grasp fails, despite all grasping conditions being met
failedGraspProbability = 0.01
#failedGraspProbability = 0.0

[observationPluginOptions]
# The error margin of the uniform distribution of the object position
objectPositionErrorMargin = 0.005

# In case Gaussian error distribution is used
jointAngleCovariance = 0.0001

observationTopic = /popcorn/observation

[rewardPluginOptions]
stepPenalty = 3
illegalMovePenalty = 250

# Penalty when keeping the hand closed while no grasp is established
illegalHandClosedPenalty = 700.0

# Penalty when having a grasp and then opening the hand
illegalHandOpenPenalty = 3.0
failedGraspPenalty = 85
exitReward = 1000
graspReward = 1750
xRotationLimit = 0.1
yRotationLimit = 0.1
rotationPenalty = 100.0

yDistPenalty = 50.0

# Preferred motion direction inside the candy box
# 0=x, 1=y
preferredMotionDirection = 1

[heuristicPluginOptions]
planningRange = 0.03
goalState = [0.85, 1.5, 1.5, -0.85, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
maxHeuristicValue = 1000.0
heuristicScalingFactor = 8.0

enteringPose = [0.0, 1.0, -0.4]
exitPose = [0.0, 1.0, 0.05]

[terminalPluginOptions]
goalLink = lwr_7_link
goalLinkPoint = [0, 0, 0]
graspStateIsTerminal = false

[initialBeliefOptions]
# For new can
lowerBound = [0.83, 0.1, 0.802, 0.0, 0.0, 0.0, 0.0, -1.2, -2.2, -0.5, 0.0, -0.8, 0.0, 0.0]
upperBound = [0.83, 0.1, 0.802, 0.0, 0.0, 0.0, 0.0, -1.2, -2.2, -0.5, 0.0, -0.8, 0.0, 0.0]

# Lower and upper bounds for the joint angle values of both arms
lowerJointPositionErrorBound = [-0.01, -0.01, -0.01, -0.01, -0.01, -0.01]
upperJointPositionErrorBound = [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
# Lower and upper bounds for object position initial belief
lowerObjectPositionErrorBound = [-0.00725, -0.00725, 0.0]
upperObjectPositionErrorBound = [0.00725, 0.00725, 0.0]

tableLinkName = box1

simulation = false

# Initial Joint values
linear = 0.10
pan_joint_angle = 0.0
tilt_joint_angle = 0.0

# Right arm initial values
right_shoulder_pan_joint_angle = 0.0
right_shoulder_lift_joint_angle = -1.2
right_arm_half_joint_angles = 0.0
right_elbow_joint_angle = -2.2
right_wrist_spherical_1_joint_angle = -0.5
right_wrist_spherical_2_joint_angle = 0.0
right_wrist_3_joint_angle = -0.8
right_gripper_finger1_joint_angle = 0.0
right_gripper_finger2_joint_angle = 0.0
right_gripper_finger3_joint_angle = 0.0

##################################################################################################
##################################################################################################
#### Problem configuration
##################################################################################################
##################################################################################################
[problem]
# Number of simulation runs
nRuns = 1

# Maximum number of steps to reach the goal
nSteps = 200

policyPath = final-ABT-policy.pol

# The planning environment SDF
planningEnvironmentPath = MovoGraspingEnvironment.sdf

# The execution environment SDF
executionEnvironmentPath = MovoGraspingEnvironment.sdf

# The robot SDF model
robotName = MovoSevenDOF

# Serialize the full world state (warning: logfiles can become huge)
enableGazeboStateLogging = false

# The discount factor of the reward model
discountFactor = 0.99

# Using state- action- and observation spaces that are normalized to [0, 1]
normalizedSpaces = false

allowCollisions = true

# The maximum time to spend on each step, in milliseconds (0 => no time limit)
stepTimeout = 750


##################################################################################################
##################################################################################################
#### State, action and observation description
##################################################################################################
##################################################################################################
[state]
##################### STATE SPACE INFO ####################################################
# First six dimensions [0-5] are object pose
# additional [6-11] dimensions correspond to the joint values controlling the right arm of the MOVO
# additional dimension [12] represents a HAND closure flag (OPEN/CLOSED)
# additional dimension [13] represents a GRASPING flag (GRASPED/NOT GRASPED)
#############################################################################################
linkPoses =[TargetObject::cylinderLink]
additionalDimensions = 8


[action]
# First six dimensions are the joint position increments (in degrees)
# or velocity increments (in degress/s)
# Last dimension is opening/closing motion
additionalDimensions = 7



#additionalDimensionLimits = [[-0.075, 0.075], [-0.075, 0.075], [-0.075, 0.075], [-0.075, 0.075], [-0.1, 0.1], [-0.075, 0.075], [0, 0]]
additionalDimensionLimits = [[-0.05, 0.05], [-0.05, 0.05], [-0.05, 0.05], [-0.05, 0.05], [-0.06, 0.06], [-0.05, 0.05], [0, 0]]

#additionalDimensionLimits = [[-0.05, 0.05], [-0.05, 0.05], [-0.05, 0.05], [-0.05, 0.05], [-0.075, 0.075], [-0.05, 0.05], [0, 0]]

# Use for verlocity control mode
#additionalDimensionLimits = [[-0.2, 0.2], [-0.2, 0.2], [-0.2, 0.2], [-0.2, 0.2], [-0.2, 0.2], [-0.2, 0.2], [0, 0]]

[observation]
ignoreGazeboSensors = true

# Object pose, hand pose, finger open/closed, graspEstablished
# First 2 [0-1] are observations on the object 2D position
# Next 6 [2-7] are on the right hand encoder angles
# Next one shows the open/close state of the hand
# Next one shows the grasp and no grasp state of the hand
additionalDimensions = 10

[options]
collisionInvariantLinks = [MovoSevenDOF::base_link, MovoSevenDOF::pan_link, MovoSevenDOF::tilt_link, MovoSevenDOF::linear_actuator_link]

##################################################################################################
##################################################################################################
#### ABT configuration
##################################################################################################
##################################################################################################
[ABT]
# The number of trajectories to simulate per time step (0 => wait for timeout)
historiesPerStep = 0

# If this is set to "true", ABT will prune the tree after every step.
pruneEveryStep = true

# If this is set to "true", ABT will reset the tree instead of modifying it when
# changes occur.
resetOnChanges = false

# The particle filter to use
particleFilter = observationModel

# The minimum number of particles for the current belief state.
minParticleCount = 1500

# Allow zero weight particle to be part of the next belief
allowZeroWeightParticles = false

# The maximum depth to search in the tree, relative to the current belief.
maximumDepth = 1000

# True if the above horizon is relative to the initial belief, and false
# if it's relative to the current belief.
isAbsoluteHorizon = false

searchHeuristic = default()
searchStrategy = ucb(3.0)

estimator = max()

actionType = discrete
numInputStepsActions = 2

actionDiscretization = [2, 2, 2, 2, 2, 2, 1]

observationType = continuous
# The maximum L2-distance between observations for them to be considered similar
#maxObservationDistance = 20.3
maxObservationDistance = 0.07
#maxObservationDistance = 2.07

# Maximum time (in seconds) to calculate a heuristc value
heuristicTimeout = 0.3

savePolicy = false
loadInitialPolicy = false
policyPath = final-0.pol

# Defines how the policy is updated after a new observation
# 'default': do nothing
# 'splitting': update policy based on observation
observationPolicyUpdate = default

[MultithreadedABT]
maxNumHistories = 50000

[changes]
hasChanges = false
changesPath = changes/manipulator-changes.txt
areDynamic = true

##################################################################################################
##################################################################################################
#### Simulation settings
##################################################################################################
##################################################################################################
[simulation]
interactive = false
particlePlotLimit = 50
